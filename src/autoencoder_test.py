# -*- coding: utf-8 -*-
"""autoencoder_draft.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1n7_zpNhMEIKOT-tfy1LudK4U_bPZmCDh
"""

import os
import math
import random
from dataclasses import dataclass
from pathlib import Path
from typing import Dict, Tuple, List, Optional
from pre_process_data import PreProcessData
from datasets import CTPatchDataset, CLASS_TO_IDX, IDX_TO_CLASS

import numpy as np
import pandas as pd
import torch
import torch.nn as nn
from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler, Subset
import matplotlib.pyplot as plt

# Since dataset and labels are already split between Experiment 1 and Experiment 2
# Maybe we just use Experiment 1 as our training data, and Experiment 2 as our testing data?
# Later we can change it (maybe combine them and do a random split/shuffle?)

@dataclass
class Config:
    # Paths to experiments
    exp1_path = Path("data/Experiment 1 - Blind/")
    exp2_path = Path("data/Experiment 2 - Open/")

    # Each row contains (uuid, slice, x, y)
    exp1_labels_csv = Path("data/labels_exp1.csv")
    exp2_labels_csv = Path("data/labels_exp2.csv")

    # Contains folders: <uuid>/volume.npz
    exp1_export_root = Path("data/export_exp1/")
    exp2_export_root = Path("data/export_exp2/")

    # So we don't hardcode "volume" everywhere
    volume_key = "volume"

    # Patch/Window around (x, y) from labels csv to feed into CNN
    patch_size = 128

    # Randomly shift crop center by this many pixels during training
    jitter_px = 6

    # Master switch for augmentations (jitter, flips, etc.)
    augment = True

    # Seed to keep random consistency
    seed = 6767

    # Training Parameters
    batch_size = 16
    epochs = 300
    lr = 0.001
    weight_decay = 0.0001
    device = "cuda" if torch.cuda.is_available() else "cpu"

    # If classes are very imbalanced, sampler helps.
    use_weighted_sampler = True

CFG = Config()

# Seed our stuff
random.seed(CFG.seed)
np.random.seed(CFG.seed)
torch.manual_seed(CFG.seed)
torch.cuda.manual_seed_all(CFG.seed
                           )

# Preprocess our dataset
print(f"Preprocessing data...\n")

# Process Experiment 1 - Blind
if not CFG.exp1_export_root.exists():
    print(f"\t{CFG.exp1_export_root} does not yet exist.")
    print(f"\tProcessing {CFG.exp1_path}...")

    data_pre_processor = PreProcessData(CFG.exp1_path, CFG.exp1_export_root)
    data_pre_processor.run()

    print(f"\t{CFG.exp1_path} processed! {CFG.exp1_export_root} has been created!\n")
else:
    print(f"\t{CFG.exp1_export_root} already exists.\n")

# Process Experiment 2 - Open
if not CFG.exp2_export_root.exists():
    print(f"\t{CFG.exp2_export_root} does not yet exist.")
    print(f"\tProcessing {CFG.exp2_path}...")

    data_pre_processor = PreProcessData(CFG.exp2_path, CFG.exp2_export_root)
    data_pre_processor.run()

    print(f"\t{CFG.exp2_path} processed! {CFG.exp2_export_root} has been created!\n")
else:
    print(f"\t{CFG.exp2_export_root} already exists.\n")

print(f"Preprocessing finished!")

#AutoEncoder Attempt

class Autoencoder(nn.Module):
    def __init__(self):
        super(Autoencoder, self).__init__()

        # ===== Encoder (matches teammate CNN) =====
        self.enc_block1 = nn.Sequential(
            nn.Conv2d(1, 16, kernel_size=3, padding=1),  # (B,16,128,128)
            nn.BatchNorm2d(16),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(2, 2)  # (B,16,64,64)
        )

        self.enc_block2 = nn.Sequential(
            nn.Conv2d(16, 32, kernel_size=3, padding=1),  # (B,32,64,64)
            nn.BatchNorm2d(32),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(2, 2)  # (B,32,32,32)
        )

        self.enc_block3 = nn.Sequential(
            nn.Conv2d(32, 64, kernel_size=3, padding=1),  # (B,64,32,32)
            nn.BatchNorm2d(64),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(2)  # NEW â†’ (B,64,16,16)
        )

        # ===== Decoder (reverse of encoder) =====
        self.dec_block1 = nn.Sequential(
            nn.ConvTranspose2d(64, 32, kernel_size=2, stride=2),  # (B,32,32,32)
            nn.BatchNorm2d(32),
            nn.ReLU(inplace=True)
        )

        self.dec_block2 = nn.Sequential(
            nn.ConvTranspose2d(32, 16, kernel_size=2, stride=2),  # (B,16,64,64)
            nn.BatchNorm2d(16),
            nn.ReLU(inplace=True)
        )

        self.dec_block3 = nn.Sequential(
            nn.ConvTranspose2d(16, 1, kernel_size=2, stride=2),  # (B,1,128,128)
            nn.Sigmoid()
        )

    def forward(self, x):
        # Encoder
        x = self.enc_block1(x)
        x = self.enc_block2(x)
        x = self.enc_block3(x)

        # Decoder
        x = self.dec_block1(x)
        x = self.dec_block2(x)
        x = self.dec_block3(x)

        return x

# Sanity Check
model = Autoencoder()
dummy = torch.randn(16, 1, 128, 128)
out = model(dummy)
print(out.shape) # Should print dimensions (16, 4)



train_ds = CTPatchDataset(CFG.exp1_export_root, CFG.exp1_labels_csv, CFG.patch_size, CFG.augment, CFG.jitter_px)
test_ds  = CTPatchDataset(CFG.exp2_export_root, CFG.exp2_labels_csv, CFG.patch_size, CFG.augment, CFG.jitter_px)

# Sanity check
x, y = train_ds[0]
print(x.shape, x.dtype, y, y.dtype)



# Normal classes are TB and TM
normal_classes = {CLASS_TO_IDX["TB"], CLASS_TO_IDX["TM"]}

normal_indices = [
    i for i, row in train_ds.df.iterrows()
    if CLASS_TO_IDX[str(row["type"])] in normal_classes
]

train_normal_ds = Subset(train_ds, normal_indices)

train_loader = DataLoader(
    train_normal_ds,
    batch_size=CFG.batch_size,
    shuffle=True,
    num_workers=0
)

# Test loader keeps all classes for anomaly evaluation
test_loader = DataLoader(
    test_ds,
    batch_size=CFG.batch_size,
    shuffle=False,
    num_workers=0
)

# Initialize model
model = Autoencoder()
model.to(CFG.device)

# Reconstruction loss
criterion = nn.MSELoss()

optimizer = torch.optim.Adam(model.parameters(), lr=CFG.lr, weight_decay=CFG.weight_decay)

logged_epochs = list()
losses = list()
validation_losses = list()

for epoch in range(CFG.epochs):
    model.train()
    running_loss = 0.0
    for xb, _ in train_loader:          # labels ignored
        xb = xb.to(CFG.device)

        optimizer.zero_grad(set_to_none=True)
        reconstructed = model(xb)       # (B,1,128,128)
        loss = criterion(reconstructed, xb)   # reconstruct input
        loss.backward()
        optimizer.step()

        running_loss += loss.item() * xb.size(0)

    train_loss = running_loss / len(train_loader.dataset)

    # Validation reconstruction loss
    model.eval()
    val_loss = 0.0
    with torch.no_grad():
        for xb, _ in test_loader:       # labels ignored
            xb = xb.to(CFG.device)
            reconstructed = model(xb)
            loss = criterion(reconstructed, xb)
            val_loss += loss.item() * xb.size(0)

    val_loss /= len(test_loader.dataset)

    if (epoch + 1) % (CFG.epochs / 25) == 0:
        print(f"epoch={epoch+1}  train_loss={train_loss:.4f}  val_recon_loss={val_loss:.4f}")
        logged_epochs.append(epoch + 1)
        losses.append(train_loss)
        validation_losses.append(val_loss)

fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(8, 8))

ax1.plot(logged_epochs, losses)
ax1.set_xlabel('Epochs')
ax1.set_ylabel('Loss')
ax1.set_title('Training Loss vs Epochs')
ax1.grid(True)

ax2.plot(logged_epochs, validation_losses)
ax2.set_xlabel('Epochs')
ax2.set_ylabel('Reconstruction Loss')
ax2.set_title('Validation Reconstruction Loss vs Epochs')
ax2.grid(True)

plt.tight_layout()
plt.show()

# Evaluate reconstruction loss per class on test set
model.eval()
class_losses = {cls: [] for cls in IDX_TO_CLASS.values()}

with torch.no_grad():
    for xb, yb in test_loader:
        xb = xb.to(CFG.device)
        reconstructed = model(xb)
        for i in range(len(yb)):
            sample_loss = criterion(reconstructed[i], xb[i]).item()
            class_losses[IDX_TO_CLASS[yb[i].item()]].append(sample_loss)

for cls, cls_losses in class_losses.items():
    print(f"Mean recon loss [{cls}]: {np.mean(cls_losses):.4f}")


model.eval()
with torch.no_grad():
    xb, yb = next(iter(test_loader))
    xb = xb.to(CFG.device)
    reconstructed = model(xb)

fig, axes = plt.subplots(2, 8, figsize=(16, 4))
for i in range(8):
    axes[0, i].imshow(xb[i].cpu().squeeze(), cmap='gray')
    axes[0, i].set_title(IDX_TO_CLASS[yb[i].item()])
    axes[0, i].axis('off')
    axes[1, i].imshow(reconstructed[i].cpu().squeeze(), cmap='gray')
    axes[1, i].axis('off')

axes[0, 0].set_ylabel("Original")
axes[1, 0].set_ylabel("Reconstructed")
plt.tight_layout()
plt.show()

